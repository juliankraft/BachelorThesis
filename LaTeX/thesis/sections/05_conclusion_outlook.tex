% Indicate the main file. Must go at the beginning of the file.
% !TEX root = ../main.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 05_conclusion_outlook
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Conclusion and Outlook}\todo{This is a starting point, needs to be extended and improved.}
\label{conclusion_outlook}

\subsection{Conclusion}

This thesis demonstrated the effectiveness of deep learning models for detecting and classifying small mammals from camera trap images.
The pretrained EfficientNet-B0 model provided superior classification accuracy, quickly converging and demonstrating robustness across validation folds.
The integration of automated detections utilizing \ac{MD}, while beneficial, revealed some room for improvement, particularly concerning misdetections and missed out detections.
It was found that some finetuning of the \ac{MD} to the specific MammaliaBox camera trap setup could improve the results.
Despite these limitations, the processing pipeline and the trained models provide a promissing start for developing a applicable tool and a workflow to reduce the manual effort.


\subsection{Outlook}
The sequence based classification did not improve the classification performance significantly as it was done in this thesis.
It still seems a very promissing approach since camera trap images are often taken in sequences, and the sequence information could be used to improve the classification performance.
Further research could explore different options for sequence-based classification.
As a first step, the models output could be evaluated on the logits level output to determine how this information could be utilized to improve the classification performance.
More sophisticated approaches could involve utilizing temporally aware models as demonstated by \textcite{muhammadTemporalSwinFPNNetNovel2024}.
Since the initial detection process using \ac{MD} could still be improved, utilizing sequence information for the detection process could be explored further.
\textcite{zotinANIMALDETECTIONUSING2019} demonstrated a promising non-\ac{DL} approach for detecting animals in camera trap images using sequence information.

Future enhancements should focus on addressing current limitations by introducing an explicit category for non-target species to improve classification accuracy and reduce false predictions with high confidence.
To allow for a broader application of the model additional categories would be needed such as the here explicitly ignored \textit{glis\_glis} species, which is a common small mammal in Switzerland on the IUCN Red List of Threatened Species.
To improve the model's robustness, while adding more categories --- possibly with limited data availability --- data augmentation techniques could be implemented, as they have been shown to enhance model performance and generalization \autocite{shortenSurveyImageData2019}.

Currently the data processing pileline is still dependent on a manual preprocessing of the image metadata to extract sequence information.
This step would benefit from automation to streamline the workflow --- ideally the input for the classification task would just be the raw images as they are retained form the camera trap.
The only available information in the \ac{EXIF} metadata, potentially allowing to group images into sequences is the timestamp.
However, this alone is not sufficient to determine the sequence length, as it does not account for the actual number of images per trigger.
Better sequence information is availabele imprinted visually on top of the images, which could be extracted using an OCR model.

An application interface or integrated software solution could be developed to enhance usability and accessibility of the model outputs for conservation practitioners.
Finally, incorporating methods such as Integrated Gradients for decision analysis could provide valuable insights into model predictions, supporting transparency and interpretability.








Standardizing sequence lengths based on typical camera settings, such as 1, 3, 5, or 10 images per trigger, may further streamline future data processing and model training pipelines.



% - implement other category - is it possible with no data for other or do i need data in order to implement it?

% - generating some more data to make glis\_glis detectable

% - creating a application for the model to make it usable

% - Integrated Gradients - decision analysis

% - The fact that the background of the images taken in the MammaliaBox is relatively uniform is not yet fully exploited.

% new data generated info to discuss:
% It is worth noting that in future use cases, the sequence length will likely be more standardized.
% The actual length will depend on the camera settings -- common settings such as 1, 3, 5, or 10 images per trigger -- which can be extracted from the EXIF information of the images.

% Data augmentation a well established way to improve model's generalization \autocite{shortenSurveyImageData2019} was implemented and considered as an option but not actually used in the end.