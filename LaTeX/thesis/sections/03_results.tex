% Indicate the main file. Must go at the beginning of the file.
% !TEX root = ../main.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 03_results
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Results}
\label{results}

    \subsection{Detection}\todo{Change Table - first image then sequence level, and make percent...}
    One of the main goals of the initial detection trough the dataset was to identify, which images are suitable for the training routine.
    The selection of images and the images discarded are shown in \autoref{tab:data_availability_after_md} the data is divided into the four categories.
    The effect of the selection is displayed for a detection threshold of \(0.25\) and \(0.5\) with the later being the finally applied one.
    On the image level the most effected category is \textit{soricidae} with \(23\%\) of the images being discarded followed by the \textit{mustela\_erminea} with \(20\%\).
    The other categories \textit{apodemus\_sp} and \textit{cricetidae} were only affected by \(7\%\) and \(8\%\) respectively.
    On the sequence level the situation is very different with only the \textit{mustela\_erminea} category being seriously effected with \(23\%\) of the sequences being discarded.
    For the other categories only around \(1\%\) of the sequences were discarded.
    The highest confidence value detections for the category \textit{mustela\_erminea} are shown in \autoref{fig:detection_mustela_best} --- all of the images display a properly detected animal.
    However, there are also some images that were not detected with a confidence value of at least \(0.25\) as shown in \autoref{fig:detection_special_nodetect}.
    Most of the images with no detection where actually empty of showed only the tip of the animal's tail as in examples 2 - 6.
    Some did show some form of obstruction, like in the examples 0 and 1 with the dragged in tube as in 1 being a common one.
    And there where quite some images with a \textit{mustela\_erminea} in the image but no detection, like in example 7 - 11.
    This occurred far more often for white fur individuals than for brown fur individuals --- this information is not statistically evaluated but rather based on a visual inspection of the images.

    % table
    \input{tables/data_availability_after_md.tex}

    \begin{figure}[]
    \centering
    \includegraphics[width=\textwidth]{figures/mustela_best.pdf}
    \caption{Highest confidence value detections for the category \textit{mustela\_erminaea} category.}
    \label{fig:detection_mustela_best}
    \end{figure}

    \begin{figure}[]
    \centering
    \includegraphics[width=\textwidth]{figures/mustela_special_nodetect.pdf}
    \caption{Selection of interessting images of the \textit{mustela\_erminaea} category with no detection within a threshold of \(0.25\).}
    \label{fig:detection_special_nodetect}
    \end{figure}


    \subsection{Classification Performance}

    All classification models performed well on their respective test sets.
    The balanced accuracy scores for each model are presented in \autoref{tab:bal_acc_by_model}.
    Generally, smaller models achieved slightly higher scores than larger ones, although these differences remained within one standard deviation.
    In particular, the pretrained EfficientNet-B0 reached the highest balanced accuracy of \(0.992\pm0.004\).
    Applying sequence level classification to the image level predictions improved balanced accuracy for every model, but only by \(0.001\) to \(0.005\), which again falls within a single standard deviation.

    Pretrained models consistently outperformed those trained from scratch, as shown in \autoref{fig:bal_acc_img}.
    EfficientNet-B0 with pretraining performs uniformly well across all folds, with only one outlier, while the non-pretrained version scored slightly lower on average and showed greater variability.
    In contrast the DenseNet-169 shows less of gap between pretrained and non-pretrained variants, with the pretrained variant performing slightly better but also increased spread across folds.
    ResNet-50 values were more dispersed for both variants, yet the pretrained model still held a clear advantage. 
    Finally, ViT-B/16 displayed the largest benefit from pretraining, alongside the greatest fold-to-fold variability in both its pretrained and non-pretrained versions.

    % table
    \input{tables/bal_acc_by_model.tex}

    \begin{figure}[ht]
    \centering
    \includegraphics{figures/bal_acc_img.pdf}
    \caption{Balanced accuracy of each model on the image-level across folds, shown separately for pretrained and non-pretrained variants. Individual fold results are plotted as points; the mean balanced accuracy is marked by a diamond; and the median is indicated by a horizontal line.}
    \label{fig:bal_acc_img}
    \end{figure}

    \subsection{Best Model}

    The model with the best performance measured by balanced accuracy was the pretrained version of EfficientNet-B0.
    Its performance per category is shown in \autoref{tab:precision_recall_fscore_support}.
    The class it performed best on was \textit{mustela\_erminea} with a value of \(0.999\) for all metrics --- this happens to be one of the classes with with relatively little samples available.
    While it performed the worse on the other underrepresented class: \textit{soricidae} with a precision of \(0.971\), recall of \(0.979\) and F1-score of \(0.975\).
    For the other, more represented classes, the model achieved very high scores above \(0.99\) for all metrics.
    
    The normalized Confusion Matrix for the best model is shown in \autoref{fig:conf_matrix_best}.
    It shows that there is basically no false positives for the class \textit{mustela\_erminea} while it was rarely confused for other classes.
    The most frequent misclassification occurred with \textit{soricidae} being falsely classified as \textit{apodemus\_sp} with a value of \(0.0184\).
    All other classes have a false positive rate of less than \(0.006\).

    % table
    \input{tables/precision_recall_fscore_support.tex}

    \begin{figure}[ht]
    \centering
    \includegraphics{figures/conf_matrix_best.pdf}
    \caption{Normalized Confusion Matrix for the best-performing model.}
    \label{fig:conf_matrix_best}
    \end{figure}
