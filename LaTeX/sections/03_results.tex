% Indicate the main file. Must go at the beginning of the file.
% !TEX root = ../main.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 03_results
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Results}
\label{results}

\subsection{Detection}
One of the main goals of the initial animal detection via \ac{MD} was to identify images suitable for the training routine.
The selection of images and the discarded ones are shown in \autoref{tab:data_availability_after_md}; the data is divided into four categories.
The effect of the selection is displayed for detection thresholds of \(0.25\) and \(0.5\), with the latter being the one finally applied.
On the image level, the most affected category is \texttt{soricidae}, with \(23\%\) of the images being discarded, followed by \texttt{mustela\_erminea} with \(20\%\).
The other categories, \texttt{apodemus\_sp} and \texttt{cricetidae}, were only affected by \(7\%\) and \(8\%\), respectively.
On the sequence level, the situation is very different, with only the \texttt{mustela\_erminea} category being seriously affected, with \(23\%\) of the sequences being discarded.
For the other categories, only around \(1\%\) of the sequences were discarded.
Some visual examinations of the results of the \ac{MD} were performed to gain a better understanding of the outcomes---some of these insights are presented in the following, focusing on the \texttt{mustela\_erminea} category.
Some of the highest-confidence detections for this category are shown in \autoref{fig:detection_mustela_best}; all the images display a properly detected animal.
The inspection of images with no detection within a threshold of \(0.25\) is shown in \autoref{fig:detection_special_nodetect}; this is a hand-picked selection of images that were interesting for the analysis.
Most of the images with no detection were actually empty or showed only the tip of the animal's tail, as seen in examples (c)--(g).
Some showed forms of obstruction, such as examples (a) and (b), with the dragged-in tube in (b) being a common one.
There were also several images with an animal clearly visible but no detection, such as in examples (h)--(l).
This occurred far more often for individuals with white fur than for those with brown fur---this observation is based on visual inspection and has not been statistically evaluated.

% table
\input{tables/data_availability_after_md.tex}

\begin{figure}[p]
\centering
\includegraphics[width=\textwidth]{figures/mustela_best.pdf}
\caption{Highest-confidence detections for the \texttt{mustela\_erminea} category.}
\label{fig:detection_mustela_best}
\end{figure}

\begin{figure}[p]
\centering
\includegraphics[width=\textwidth]{figures/mustela_special_nodetect.pdf}
\caption{Hand-picked selection of \texttt{mustela\_erminea} images with no detection at a threshold of \(0.25\).}
\label{fig:detection_special_nodetect}
\end{figure}

\subsection{Classification Performance}
All classification models performed well on their respective test sets.
The \ac{BA} scores for each model architecture are presented in \autoref{tab:bal_acc_by_model} for the pretrained and non-pretrained variants.
Generally, smaller architectures achieved slightly higher scores than larger ones, although these differences remained within one standard deviation.
In particular, the pretrained EfficientNet-B0 reached the highest \ac{BA} of \(0.992\pm0.004\).
Applying sequence-level classification to the image-level predictions improved \ac{BA} for every model architecture, but only by \(0.001\) to \(0.005\), which again falls within a single standard deviation.

Pretrained versions consistently outperformed those trained from scratch, as shown in \autoref{fig:bal_acc_img} and \autoref{tab:bal_acc_by_model}.
EfficientNet-B0 with pretraining performed uniformly well across all folds, with only one outlier, while the non-pretrained version scored slightly lower on average and showed greater variability.
In contrast, DenseNet-169 showed less of a gap between pretrained and non-pretrained variants, with the pretrained version performing slightly better but also showing increased spread across folds.
ResNet-50 values were more dispersed for both variants, yet the pretrained model still held a clear advantage.
Finally, ViT-B/16 displayed the largest benefit from pretraining, alongside the greatest fold-to-fold variability in both its pretrained and non-pretrained versions.

% table
\setlength{\fboxsep}{1pt}
\input{tables/bal_acc_by_model.tex}
\setlength{\fboxsep}{3pt}

\begin{figure}[ht]
\centering
\includegraphics{figures/bal_acc_img.pdf}
\caption{
    \acs{BA} of each model at image level across folds, shown separately for pretrained and non-pretrained variants.
    Individual fold results are plotted as points, the mean \acs{BA} is marked by a diamond, and the median is indicated by a horizontal line.
    }
\label{fig:bal_acc_img}
\end{figure}

\subsection{Best-Performing Model Architecture}
The model architecture that achieved the best performance, as measured by \ac{BA}, was EfficientNet-B0 with pretraining.
\autoref{fig:training_metrics_best_model} shows the validation metrics for each cross-validation fold across all epochs; note that accuracy is reported in this figure instead of \ac{BA}.
For all folds, the best version, defined by the lowest validation loss, occurred within the first 3 epochs, while the accuracy kept increasing.
Its performance per category is shown in \autoref{tab:precision_recall_fscore_support}.
The class it performed best on was \texttt{mustela\_erminea}, with a value of \(0.999\) for all metrics---this happens to be one of the classes with relatively few samples available.
It performed the worst on the other underrepresented class, \texttt{soricidae}, with a precision of \(0.971\), recall of \(0.979\) and F1-score of \(0.975\).
For the other, more represented classes, the model achieved very high scores above \(0.99\) for all metrics.

The normalized \ac{CM} for the best model is shown in \autoref{fig:conf_matrix_best}.
It shows that there were essentially no false positives for the class \texttt{mustela\_erminea}, while it was rarely confused with other classes.
The most frequent misclassification occurred with \texttt{soricidae} being falsely classified as \texttt{apodemus\_sp}, with a value of \(0.0184\).
All other classes had a false positive rate of less than \(0.006\).

The Spearman's rank correlation coefficient between the detection and the classification confidence was $\rho = 0.092$ for correctly classified samples and $\rho = 0.276$ for misclassified samples.
This suggests that there is a very weak positive monotonic relationship between detection confidence and classification confidence for correctly classified images, and a weak positive correlation for misclassified images.

\begin{figure}[ht]
\centering
\includegraphics{figures/training_metrics_best_model.pdf}
\caption{
    Validation loss and accuracy of the pretrained EfficientNet-B0 across all cross-validation folds.
    In the loss subplot, the lowest value per fold is marked with a dot, indicating the best-performing epoch.
    In the accuracy subplot, the highest value per fold is similarly marked.
    }
\label{fig:training_metrics_best_model}
\end{figure}

% table
\input{tables/precision_recall_fscore_support.tex}

\begin{figure}[ht]
\centering
\includegraphics{figures/conf_matrix_best.pdf}
\caption{Normalized \acs{CM} for the pretrained EfficientNet-B0.}
\label{fig:conf_matrix_best}
\end{figure}