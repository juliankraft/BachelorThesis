{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import csv\n",
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Any, TypedDict\n",
    "\n",
    "from megadetector.detection.run_detector import load_detector, model_string_to_model_version\n",
    "from megadetector.detection.run_detector_batch import process_images, write_results_to_file\n",
    "\n",
    "from os import PathLike\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_path_config(path_to_config):\n",
    "    with open(path_to_config, 'r') as f:\n",
    "        path_config = yaml.safe_load(f)\n",
    "    return {k: Path(v) for k, v in path_config.items()}\n",
    "\n",
    "paths = load_path_config('/cfs/earth/scratch/kraftjul/BA/code/path_config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MegaDetectorRunner:\n",
    "    \"\"\"\n",
    "    A class to run the MegaDetector model on images. Designed to be used on a set of image sequences,\n",
    "    only loading the model once and running it on all sequences.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_path : str | PathLike\n",
    "        Path to the MegaDetector model file. Or a string representing the model version available online.\n",
    "    confidence : float\n",
    "        Confidence threshold for the model. Default is 0.25.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            model_path: str | PathLike, \n",
    "            confidence: float = 0.25\n",
    "            ):\n",
    "        \n",
    "        self.model = load_detector(str(model_path))\n",
    "        self.confidence = confidence\n",
    "\n",
    "    def run_on_images(\n",
    "            self,\n",
    "            images: list[PathLike],\n",
    "            output_file_path: PathLike = None,\n",
    "            ):\n",
    "\n",
    "        results = process_images(\n",
    "            im_files=images,\n",
    "            detector=self.model,\n",
    "            confidence_threshold=self.confidence,\n",
    "            quiet=True\n",
    "        )\n",
    "\n",
    "        all_confidences = []\n",
    "\n",
    "        for r in results:\n",
    "            r[\"file\"] = r[\"file\"].name\n",
    "\n",
    "            r[\"detections\"] = [\n",
    "                det for det in r.get(\"detections\", [])\n",
    "                if det[\"category\"] == \"1\"\n",
    "            ]\n",
    "        \n",
    "            all_confidences.extend(det[\"conf\"] for det in r[\"detections\"])\n",
    "\n",
    "        all_confidences.sort(reverse=True)\n",
    "        \n",
    "        if output_file_path is not None:\n",
    "            with open(output_file_path, \"w\") as f:\n",
    "                json.dump(results, f, indent=2)\n",
    "\n",
    "        return all_confidences      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MammaliaData(Dataset):\n",
    "    \"\"\"\n",
    "    A class to load and process the Mammalia dataset. It can be uset for the initial detection of the images\n",
    "    utilizing the MegaDetector model, or for training a custom model for classification on the detected images.\n",
    "    The dataset is divided into training and testing sets based on the sequence IDs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path_labelfiles : str | PathLike\n",
    "        Path to the directory containing the label files.\n",
    "    path_to_dataset : str | PathLike\n",
    "        Path to the main directory of the dataset, referenced in the labelfiles.\n",
    "    path_to_detector_output : str | PathLike\n",
    "        Path to the directory where the detector output is available for training or where the output will be saved\n",
    "        if in detect mode.\n",
    "    categories_to_drop : list[str], optional\n",
    "        By default all non-empty labels are used. To drop certain labels from the dataset, provide a list of labels to drop.\n",
    "        In detect mode, this parameter is ignored.\n",
    "    detector_model : str\n",
    "        Can be either a path to the model file or a string representing the model version available online.\n",
    "        This parameter is only used in detect mode. It specifies the model version to be used for detection.\n",
    "        The default is \"MDV5A\". The parameter is ignored in train and test mode.\n",
    "    detection_confidence : float\n",
    "        The detection in detection mode is done with a confidence of 0.25 by default. If for training or testing\n",
    "        a higher confidence is needed, this parameter can be set to a higher value.\n",
    "        The default is 0.25.\n",
    "    sample_length : int\n",
    "        For trainig this parameter specifies the range (1 - sample_length) of randomly seletded samples per sequence.\n",
    "        For testing this parameter specifies the maximum number of samples per sequence.\n",
    "        The default is 10.\n",
    "    sample_img_size : [int, int]\n",
    "        The size to which the detected areas are resized. The default is [224, 224].\n",
    "    mode : str\n",
    "        The mode in which the dataset is used. Can be either 'train', 'test' or 'detect'.\n",
    "        In detect mode, the model is used to detect animals in the images. In train and test mode, the model is used\n",
    "        to train or test a custom model for classification.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            path_labelfiles: str | PathLike,\n",
    "            path_to_dataset: str | PathLike,\n",
    "            path_to_detector_output: str | PathLike,\n",
    "            categories_to_drop: list[str] = None,\n",
    "            detector_model: str = \"mdv5a\",\n",
    "            detection_confidence: float = 0.25,\n",
    "            sample_length: int = 10,\n",
    "            sample_img_size: [int, int] = [224, 224],\n",
    "            mode: str = 'train',\n",
    "            ):\n",
    "        super().__init__()\n",
    "\n",
    "        if mode in ['train', 'test', 'detect']:\n",
    "            self.mode = mode\n",
    "        else:\n",
    "            raise ValueError(\"Please choose a mode from ['train', 'test', 'detect'].\")\n",
    "\n",
    "        path_labelfiles = Path(path_labelfiles)\n",
    "        if not path_labelfiles.exists():\n",
    "            raise ValueError(\"The path to the label files does not exist.\")\n",
    "        self.path_labelfiles = path_labelfiles\n",
    "        \n",
    "        path_to_dataset = Path(path_to_dataset)\n",
    "        if not path_to_dataset.exists():\n",
    "            raise ValueError(\"The path to the dataset does not exist.\")\n",
    "        self.path_to_dataset = path_to_dataset\n",
    "        \n",
    "        path_to_detector_output = Path(path_to_detector_output)\n",
    "        if self.mode != 'detect':\n",
    "            if not path_to_detector_output.exists():\n",
    "                raise ValueError(\"The path to the detector output does not exist. Detection output must be available for training.\")\n",
    "        else:    \n",
    "            if not path_to_detector_output.exists():\n",
    "                os.makedirs(path_to_detector_output)\n",
    "            elif any(path_to_detector_output.iterdir()):\n",
    "                raise ValueError(\"The path to the detector output contains files. Please clear or choose a different path.\")\n",
    "        self.path_to_detector_output = path_to_detector_output\n",
    "        \n",
    "        self.labelfiles = self.getting_all_files_of_type(self.path_labelfiles, file_type='.csv')\n",
    "\n",
    "        if not self.mode == 'detect':\n",
    "            self.categories_to_drop = categories_to_drop if categories_to_drop is not None else []\n",
    "        else: \n",
    "            self.categories_to_drop = []\n",
    "\n",
    "        self.ds_full = self.reading_all_metadata(\n",
    "            list_of_files=self.labelfiles, \n",
    "            categories_to_drop=self.categories_to_drop\n",
    "            )\n",
    "        \n",
    "        if self.ds_full['seq_id'].duplicated().any():\n",
    "            duplicates = self.ds_full[self.ds_full['seq_id'].duplicated()]['seq_id'].tolist()\n",
    "            raise ValueError(f\"Duplicate seq_id(s) found in metadata: {duplicates[:5]} ...\")\n",
    "        \n",
    "        if not self.mode == 'detect':\n",
    "            train_seq_ids, test_seq_ids = train_test_split(\n",
    "                self.ds_full['seq_id'],\n",
    "                test_size=0.2,\n",
    "                random_state=55,\n",
    "                stratify=self.ds_full['label2']\n",
    "                )\n",
    "            \n",
    "            if self.mode == 'train':\n",
    "                active_seq_ids = train_seq_ids\n",
    "            elif self.mode == 'test':\n",
    "                active_seq_ids = test_seq_ids\n",
    "            \n",
    "            active_set = set(active_seq_ids)\n",
    "            no_detected_set = set(self.get_seq_ids_with_no_detectection())\n",
    "\n",
    "            excluded_seq_ids = list(active_set & no_detected_set)\n",
    "            if excluded_seq_ids:\n",
    "                warnings.warn(\n",
    "                    f'{len(excluded_seq_ids)} sequences had no detections above {self.detection_confidence} confidence.\\n'\n",
    "                    f'Example: {excluded_seq_ids[:10]}',\n",
    "                    UserWarning\n",
    "                )\n",
    "\n",
    "            active_seq_ids = list(active_set - no_detected_set)\n",
    "\n",
    "        else:\n",
    "            active_seq_ids = self.ds_full['seq_id'].unique().tolist()\n",
    "\n",
    "        self.ds = self.ds_full[self.ds_full['seq_id'].isin(active_seq_ids)]\n",
    "        self.seq_ids = self.ds['seq_id'].tolist()\n",
    "        \n",
    "        if mode == 'detect':\n",
    "            self.detector_model = detector_model\n",
    "            \n",
    "            if self.detector_model not in model_string_to_model_version.keys():\n",
    "                raise ValueError(f\"The model {self.detector_model} is not supported. Please choose from {model_string_to_model_version.keys()}.\")\n",
    "            \n",
    "            self.run_detector()\n",
    "        \n",
    "        if detection_confidence < 0.25:\n",
    "            raise ValueError(\"Detection confidence must be at least 0.25.\")\n",
    "        self.detection_confidence = detection_confidence\n",
    "        self.sample_length = sample_length\n",
    "        self.sample_img_size = sample_img_size\n",
    "\n",
    "    def getting_all_files_of_type(\n",
    "            self, \n",
    "            path: str | PathLike, \n",
    "            file_type: str = None, \n",
    "            get_full_path: bool = True\n",
    "            ) -> list[str]:\n",
    "        \n",
    "        path = Path(path)\n",
    "        files = []\n",
    "        for file in os.listdir(path):\n",
    "            if file_type is None or file.endswith(file_type):\n",
    "                if get_full_path:\n",
    "                    files.append(path / file)\n",
    "                else:\n",
    "                    files.append(file)\n",
    "        return files\n",
    "    \n",
    "    def reading_all_metadata(\n",
    "            self,\n",
    "            list_of_files: list[PathLike],\n",
    "            categories_to_drop: list[str]\n",
    "            ) -> pd.DataFrame:\n",
    "        \n",
    "        metadata = pd.DataFrame()\n",
    "        for file in list_of_files:\n",
    "            metadata = pd.concat([metadata, pd.read_csv(file)], ignore_index=True)\n",
    "            metadata = metadata.dropna(subset=['label2'])\n",
    "            metadata = metadata[~metadata['label2'].isin(categories_to_drop)]\n",
    "        return metadata\n",
    "    \n",
    "    def get_seq_ids_with_no_detectection(\n",
    "            self,\n",
    "            ) -> list[int]:\n",
    "        detection_summary = pd.read_csv(self.path_to_detector_output / \"detection_summary.csv\", nrows=2)\n",
    "        return detection_summary[detection_summary[\"max_conf\"] < self.detection_confidence][\"seq_id\"].tolist()\n",
    "    \n",
    "    def get_all_images_of_sequence(\n",
    "            self, \n",
    "            seq_id: int,\n",
    "            )-> dict[str, PathLike]:\n",
    "        image_dict = {}\n",
    "        row = self.ds_full.loc[self.ds_full['seq_id'] == seq_id].squeeze()\n",
    "        seq_path = Path(row['Directory'])\n",
    "        all_files = row['all_files'].split(',')\n",
    "        for file in all_files:\n",
    "            image_dict[file] = self.path_to_dataset / seq_path / file\n",
    "        return image_dict\n",
    "\n",
    "    def run_detector(\n",
    "            self,\n",
    "            ) -> None:\n",
    "        \n",
    "        if self.mode != 'detect':\n",
    "            raise ValueError(\"Only available if dataset is in detect mode.\")\n",
    "        \n",
    "        runner = MegaDetectorRunner(\n",
    "            model_path=self.detector_model,\n",
    "            confidence=0.25\n",
    "            )\n",
    "\n",
    "        sequences = self.ds['seq_id'].unique().tolist()\n",
    "\n",
    "        detection_rows = []\n",
    "\n",
    "        for seq_id in sequences:\n",
    "            seq_images = list(self.get_all_images_of_sequence(seq_id).values())\n",
    "            output_file_path = self.path_to_detector_output / f\"{seq_id}.json\"\n",
    "            detections = runner.run_on_images(\n",
    "                images=seq_images,\n",
    "                output_file_path=output_file_path\n",
    "                )\n",
    "\n",
    "            detection_row = {\n",
    "                    \"seq_id\": seq_id,\n",
    "                    \"max_conf\": max(detections) if len(detections) > 0 else 0,\n",
    "                    \"n_detections\": len(detections),\n",
    "                    \"conf_list\": json.dumps(detections)\n",
    "                }\n",
    "            \n",
    "            detection_rows.append(detection_row)\n",
    "        \n",
    "        all_detections = pd.DataFrame(detection_rows, columns=[\"seq_id\", \"max_conf\", \"n_detections\", \"conf_list\"])\n",
    "\n",
    "        all_detections.to_csv(\n",
    "            self.path_to_detector_output / \"detection_summary.csv\", \n",
    "            index=False,\n",
    "            quoting=csv.QUOTE_NONNUMERIC\n",
    "            )\n",
    "            \n",
    "    def getting_bb_list_for_seq(\n",
    "            self,\n",
    "            seq_id: int,\n",
    "            confidence: float = None,\n",
    "            ) -> list[dict]:\n",
    "        \n",
    "        if self.mode != 'detect':\n",
    "            raise ValueError(\"Only available if dataset is in detect mode.\")\n",
    "        \n",
    "        if confidence is None:\n",
    "            confidence = self.detection_confidence\n",
    "\n",
    "        path_to_detection_results = self.path_to_detector_output / f\"{seq_id}.json\"\n",
    "        with open(path_to_detection_results, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        bb_list = []\n",
    "\n",
    "        for entry in data:\n",
    "            file_name = entry['file']\n",
    "            detections = entry.get('detections', [])\n",
    "\n",
    "            for det in detections:\n",
    "                if det['category'] == \"1\" and det['conf'] >= confidence:\n",
    "                    bb_list({\n",
    "                        'file': file_name,\n",
    "                        'conf': det['conf'],\n",
    "                        'bbox': det['bbox']\n",
    "                    })\n",
    "        \n",
    "        bb_list = sorted(bb_list, key=lambda x: x['conf'], reverse=True)\n",
    "\n",
    "        return bb_list\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Any: # still to be implemented\n",
    "        seq_id = self.seq_ids[index]\n",
    "\n",
    "        images = self.get_all_images_of_sequence(seq_id)\n",
    "        bounding_boxes = self.getting_bb_list_for_seq(seq_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MammaliaData(\n",
    "    path_to_dataset=paths['dataset'],\n",
    "    path_labelfiles='/cfs/earth/scratch/kraftjul/BA/output/test_set/',\n",
    "    path_to_detector_output='/cfs/earth/scratch/kraftjul/BA/output/test2_MD_out',\n",
    "    mode='test',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([PosixPath('/cfs/earth/scratch/iunr/shared/iunr-mammaliabox/dataset/sessions/session_01/H_2/RCNX0021.JPG'), PosixPath('/cfs/earth/scratch/iunr/shared/iunr-mammaliabox/dataset/sessions/session_01/H_2/RCNX0022.JPG'), PosixPath('/cfs/earth/scratch/iunr/shared/iunr-mammaliabox/dataset/sessions/session_01/H_2/RCNX0023.JPG')])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_all_images_of_sequence(1000003).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bypassing download of already-downloaded file md_v5a.0.0.pt\n",
      "Model v5a.0.0 available at /tmp/megadetector_models/md_v5a.0.0.pt\n",
      "Bypassing imports for model type yolov5\n",
      "Loading PT detector with compatibility mode classic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs\n",
      "Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "dataset = MammaliaData(\n",
    "    path_to_dataset=paths['dataset'],\n",
    "    path_labelfiles='/cfs/earth/scratch/kraftjul/BA/output/test_set/',\n",
    "    path_to_detector_output='/cfs/earth/scratch/kraftjul/BA/output/test2_MD_out',\n",
    "    mode='detect',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1002472,\n",
       " 1001367,\n",
       " 4004783,\n",
       " 4004751,\n",
       " 4006753,\n",
       " 4004487,\n",
       " 4000232,\n",
       " 4004905,\n",
       " 1000883,\n",
       " 4006146,\n",
       " 1000612,\n",
       " 1001197,\n",
       " 4006473,\n",
       " 1000441,\n",
       " 4013208,\n",
       " 4016418,\n",
       " 6000305,\n",
       " 6000652,\n",
       " 6000414,\n",
       " 6000794,\n",
       " 6000402,\n",
       " 6000301,\n",
       " 1000003,\n",
       " 6000358,\n",
       " 4014783,\n",
       " 4010560,\n",
       " 4010914,\n",
       " 4012988,\n",
       " 4017512,\n",
       " 1000210,\n",
       " 4017527,\n",
       " 4014264]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.seq_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('sessions/session_01/H550HF08161327_1/IMG_0187.JPG'),\n",
       " PosixPath('sessions/session_01/H550HF08161327_1/IMG_0188.JPG'),\n",
       " PosixPath('sessions/session_01/H550HF08161327_1/IMG_0189.JPG'),\n",
       " PosixPath('sessions/session_01/H550HF08161327_1/IMG_0190.JPG'),\n",
       " PosixPath('sessions/session_01/H550HF08161327_1/IMG_0191.JPG'),\n",
       " PosixPath('sessions/session_01/H550HF08161327_1/IMG_0192.JPG'),\n",
       " PosixPath('sessions/session_01/H550HF08161327_1/IMG_0193.JPG'),\n",
       " PosixPath('sessions/session_01/H550HF08161327_1/IMG_0194.JPG'),\n",
       " PosixPath('sessions/session_01/H550HF08161327_1/IMG_0195.JPG')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract list of all sequences from pd_dataframe\n",
    "\n",
    "\n",
    "dataset.get_all_images_of_sequence(1002472)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bypassing download of already-downloaded file md_v5a.0.0.pt\n",
      "Model v5a.0.0 available at /tmp/megadetector_models/md_v5a.0.0.pt\n",
      "PyTorch reports 0 available CUDA devices\n",
      "GPU available: False\n",
      "Loading PT detector with compatibility mode classic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Fusing layers... \n",
      "[W331 10:32:31.782568958 NNPACK.cpp:62] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs\n",
      "Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 25.97 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image /cfs/earth/scratch/iunr/shared/iunr-mammaliabox/dataset/sessions/session_01/H_1/RCNX0001.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image /cfs/earth/scratch/iunr/shared/iunr-mammaliabox/dataset/sessions/session_01/H_1/RCNX0002.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image /cfs/earth/scratch/iunr/shared/iunr-mammaliabox/dataset/sessions/session_01/H_1/RCNX0003.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: no metadata for unknown detector version unknown\n",
      "Output file saved at /cfs/earth/scratch/kraftjul/BA/output/megadetector_output_tes2.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'images': [{'file': 'RCNX0001.JPG',\n",
       "   'detections': [{'category': '1',\n",
       "     'conf': 0.771,\n",
       "     'bbox': [0.2236, 0.5555, 0.1225, 0.1402]},\n",
       "    {'category': '2', 'conf': 0.184, 'bbox': [0.7783, 0.0215, 0.2216, 0.227]},\n",
       "    {'category': '2', 'conf': 0.055, 'bbox': [0.0004, 0.0201, 0.2758, 0.3895]},\n",
       "    {'category': '2',\n",
       "     'conf': 0.019,\n",
       "     'bbox': [0.7812, 0.0215, 0.2187, 0.8006]}]},\n",
       "  {'file': 'RCNX0002.JPG',\n",
       "   'detections': [{'category': '1',\n",
       "     'conf': 0.487,\n",
       "     'bbox': [0.2197, 0.5701, 0.185, 0.1354]},\n",
       "    {'category': '2', 'conf': 0.087, 'bbox': [0.7802, 0.0215, 0.2197, 0.2187]},\n",
       "    {'category': '2', 'conf': 0.084, 'bbox': [0.0004, 0.0208, 0.27, 0.3923]},\n",
       "    {'category': '2', 'conf': 0.031, 'bbox': [0.0004, 0.0222, 0.267, 0.9569]},\n",
       "    {'category': '2', 'conf': 0.019, 'bbox': [0.7822, 0.0215, 0.2177, 0.7951]},\n",
       "    {'category': '3', 'conf': 0.015, 'bbox': [0.0, 0.0256, 1.0, 0.9673]},\n",
       "    {'category': '1', 'conf': 0.005, 'bbox': [0.0078, 0.0222, 0.9916, 0.3201]},\n",
       "    {'category': '1',\n",
       "     'conf': 0.005,\n",
       "     'bbox': [0.0161, 0.0222, 0.8569, 0.6854]}]},\n",
       "  {'file': 'RCNX0003.JPG',\n",
       "   'detections': [{'category': '2',\n",
       "     'conf': 0.307,\n",
       "     'bbox': [0.0004, 0.0208, 0.2797, 0.3847]},\n",
       "    {'category': '2', 'conf': 0.168, 'bbox': [0.7792, 0.0215, 0.2207, 0.2243]},\n",
       "    {'category': '2', 'conf': 0.086, 'bbox': [0.0004, 0.0194, 0.2817, 0.9597]},\n",
       "    {'category': '2', 'conf': 0.026, 'bbox': [0.0, 0.025, 1.0, 0.9631]},\n",
       "    {'category': '2', 'conf': 0.025, 'bbox': [0.7822, 0.0208, 0.2177, 0.7965]},\n",
       "    {'category': '3', 'conf': 0.014, 'bbox': [0.0004, 0.0243, 0.9995, 0.9631]},\n",
       "    {'category': '2', 'conf': 0.013, 'bbox': [0.0, 0.0222, 0.1279, 0.9527]}]}],\n",
       " 'detection_categories': {'1': 'animal', '2': 'person', '3': 'vehicle'},\n",
       " 'info': {'detection_completion_time': '2025-03-31 10:32:34',\n",
       "  'format_version': '1.4',\n",
       "  'detector': 'unknown',\n",
       "  'detector_metadata': {'megadetector_version': 'unknown',\n",
       "   'typical_detection_threshold': 0.5,\n",
       "   'conservative_detection_threshold': 0.25}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick a folder to run MD on recursively, and an output file\n",
    "image_folder = os.path.expanduser('/cfs/earth/scratch/iunr/shared/iunr-mammaliabox/dataset/sessions/session_01/H_1')\n",
    "output_file = os.path.expanduser('/cfs/earth/scratch/kraftjul/BA/output/megadetector_output_tes2.json')\n",
    "\n",
    "# Recursively find images\n",
    "image_file_names = path_utils.find_images(image_folder,recursive=True)\n",
    "\n",
    "# This will automatically download MDv5a; you can also specify a filename.\n",
    "results = load_and_run_detector_batch('MDV5A', image_file_names)\n",
    "\n",
    "# Write results to a format that Timelapse and other downstream tools like.\n",
    "write_results_to_file(results,\n",
    "                      output_file,\n",
    "                      relative_path_base=image_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/cfs/earth/scratch/iunr/shared/iunr-mammaliabox/dataset/sessions/session_01/H_1/RCNX0001.JPG',\n",
       " '/cfs/earth/scratch/iunr/shared/iunr-mammaliabox/dataset/sessions/session_01/H_1/RCNX0002.JPG',\n",
       " '/cfs/earth/scratch/iunr/shared/iunr-mammaliabox/dataset/sessions/session_01/H_1/RCNX0003.JPG']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_file_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
